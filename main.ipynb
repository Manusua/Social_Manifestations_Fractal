{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/csv/\"\n",
    "file1 = \"hashtag_usages_per_hour_9n_9ngranmarchaporlajusticia_weighted.txt\"\n",
    "file2 = \"hashtag_usages_per_hour_noaltarifazo_ruidazonacional_weighted.txt\"\n",
    "graphs_folder = \"graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([436983, 436984, 436985, 436986, 436987, 436988, 436989, 436990,\n",
       "       436991, 436992, 436993, 436994, 436995, 436996, 436997, 436998,\n",
       "       436999, 437000, 437001, 437002, 437003, 437004, 437005, 437006,\n",
       "       437007, 437008, 437009, 437010, 437011, 437012, 437013, 437014,\n",
       "       437015, 437016, 437017, 437018, 437019, 437020, 437021, 437022,\n",
       "       437023, 437024, 437025, 437026, 437027, 437028, 437029, 437030,\n",
       "       437031, 437032, 437033, 437034, 437035, 437036, 437037, 437038,\n",
       "       437039, 437040, 437041, 437042, 437043, 437044, 437045, 437046,\n",
       "       437047, 437048, 437049, 437050, 437051, 437052, 437053, 437054,\n",
       "       437055, 437056, 437057, 437058, 437059, 437060, 437061, 437062,\n",
       "       437063, 437064, 437065, 437066, 437067, 437068, 437069, 437070,\n",
       "       437071, 437072, 437073, 437074, 437075, 437076, 437077, 437078,\n",
       "       437079])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_folder + file1, sep=' ')\n",
    "df_h = df[\"hour\"].unique()\n",
    "np.sort(df_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for hour in df_h:\n",
    "    print(hour)\n",
    "    df_aux = df[(df[\"hour\"] == hour)]\n",
    "    df_users = df_aux[\"user\"].unique()\n",
    "    print(\"num users: \", df_users.shape[0])\n",
    "    G.add_nodes_from(df_users)\n",
    "    for user in tqdm.tqdm(df_users):\n",
    "        df_user_hastag = df_aux.loc[df_aux[\"user\"] == user]\n",
    "        df_user_hastag = df_user_hastag[\"hashtag\"]\n",
    "        for hashtag in df_user_hastag:\n",
    "            df_hashtag = df_aux.loc[df_aux[\"hashtag\"] == hashtag]\n",
    "            df_hashtag = df_hashtag[\"user\"]\n",
    "            for us in df_hashtag:\n",
    "                if us != user:\n",
    "                    if G.has_edge(user, us):\n",
    "                        G[user][us][\"weight\"] += 1\n",
    "                    elif G.has_edge(us, user):\n",
    "                        print(\"B\")                    \n",
    "                        G[us][user][\"weight\"] += 1\n",
    "                    else:\n",
    "                        G.add_edge(user, us, weight = 1)\n",
    "    nx.write_gexf(G, graphs_folder + \"users_sharing_hashtags_\" + str(hour) + \".gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num users:  8022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8022 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 3639/8022 [14:25<18:18,  3.99it/s]   "
     ]
    }
   ],
   "source": [
    "# Creo red de usuarios que comparten hastags\n",
    "G = nx.Graph()\n",
    "df_users = df[\"user\"].unique()\n",
    "print(\"num users: \", df_users.shape[0])\n",
    "G.add_nodes_from(df_users)\n",
    "for user in tqdm.tqdm(df_users):\n",
    "    df_user_hastag = df.loc[df[\"user\"] == user]\n",
    "    df_user_hastag = df_user_hastag[\"hashtag\"]\n",
    "    #df_user_hastag.columns[1] = \"hashtag\"\n",
    "    #print(df_user_hastag)\n",
    "    #print(\"Encontrados \", df_user_hastag.shape[0], \"hashtags del usuario \", user)\n",
    "    for hashtag in df_user_hastag:\n",
    "        df_hashtag = df.loc[df[\"hashtag\"] == hashtag]\n",
    "        df_hashtag = df_hashtag[\"user\"]\n",
    "        #print(df_hashtag.shape[0] , \" usuarios comentaron sobre el hastag \", hashtag)\n",
    "        for us in df_hashtag:\n",
    "            # TODO Si buscamos eficiencia se puede quitar y añadir todas las conexiones y luego simplemente quitar la propia\n",
    "            if us != user:\n",
    "                # TODO Es no dirigido asi que el orden da igual(?)\n",
    "                if G.has_edge(user, us):\n",
    "                    #print(\"A\")\n",
    "                    G[user][us][\"weight\"] += 1\n",
    "                elif G.has_edge(us, user):\n",
    "                    print(\"B\")                    \n",
    "                    G[us][user][\"weight\"] += 1\n",
    "                else:\n",
    "                    G.add_edge(user, us, weight = 1)\n",
    "nx.write_gexf(G, graphs_folder + \"users_sharing_hashtags.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo red de hastags que comparten usuarios\n",
    "G = nx.Graph()\n",
    "for hour in df_h:\n",
    "    print(hour)\n",
    "    df_aux = df[(df[\"hour\"] == hour)]\n",
    "    df_hashtags = df_aux[\"hashtag\"].unique()\n",
    "    print(\"num hashtags: \", df_hashtags.shape[0])\n",
    "    G.add_nodes_from(df_hashtags)\n",
    "    for hashtag in tqdm.tqdm(df_hashtags):\n",
    "        df_hashtag_user = df_aux.loc[df_aux[\"hashtag\"] == hashtag]\n",
    "        df_hashtag_user = df_hashtag_user[\"user\"]\n",
    "        for user in df_hashtag_user:\n",
    "            df_user = df_aux.loc[df_aux[\"user\"] == user]\n",
    "            df_user = df_user[\"hashtag\"]\n",
    "            #print(df_hashtag.shape[0] , \" usuarios comentaron sobre el hastag \", hashtag)\n",
    "            for hash in df_user:\n",
    "                # TODO Si buscamos eficiencia se puede quitar y añadir todas las conexiones y luego simplemente quitar la propia\n",
    "                if hash != hashtag:\n",
    "                    # TODO Es no dirigido asi que el orden da igual(?)\n",
    "                    if G.has_edge(hashtag, hash):\n",
    "                        #print(\"A\")\n",
    "                        G[hashtag][hash][\"weight\"] += 1\n",
    "                    elif G.has_edge(hash, hashtag):\n",
    "                        print(\"B\")                    \n",
    "                        G[hash][hashtag][\"weight\"] += 1\n",
    "                    else:\n",
    "                        G.add_edge(hashtag, hash, weight = 1)\n",
    "    nx.write_gexf(G, graphs_folder + \"hashtags_sharing_users_\" + str(hour) + \".gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nodes_subgraph(G, treshold):\n",
    "    F = nx.Graph()\n",
    "    for node in G.nodes():\n",
    "        # Comprobamos si el grado del nodo es mayor que el umbral\n",
    "        if G.degree[node] > treshold:\n",
    "            # Añadimos el nodo\n",
    "            F.add_node(node)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges_subgraph(G, F):\n",
    "    for node in F.nodes():\n",
    "        # Se itera sobre los vecinos en G de cada nodo y vemos si estan en F\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if neighbor in F.nodes():\n",
    "                # Se añade la arista si no existe ya\n",
    "                if not neighbor in F.neighbors(node):\n",
    "                    F.add_edge(node, neighbor)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tresh_normalization(G, treshold):\n",
    "    F = add_nodes_subgraph(G, treshold)\n",
    "    \n",
    "    # Ahora añadimos las aristas de G de los nodos en el subgrafo F\n",
    "    F = add_edges_subgraph(G, F)\n",
    "\n",
    "    return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_clust(G):\n",
    "    dict_tres = {}\n",
    "    for i in tqdm.tqdm(range(600)):\n",
    "        treshold = i\n",
    "        F = tresh_normalization(G,treshold)\n",
    "        #TODO mirar cugraph https://github.com/rapidsai/cugraph/tree/branch-24.06/python/nx-cugraph\n",
    "        clust  = nx.clustering(F)\n",
    "        avg_clust = np.mean(np.array(list(clust.values())))\n",
    "        #print(\"Cargado el subgrafo con umbral \" + str(treshold) + ', numero de nodos: ' + str(F.number_of_nodes()) + ', numero de aristas: ' + str(F.number_of_edges()) + ', clusterizacion media: ' + str(avg_clust))\n",
    "        dict_tres[treshold] = avg_clust\n",
    "    return dict_tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clust(dict_tres, name_graph):\n",
    "    # Obtener las claves y los valores del diccionario\n",
    "    claves = list(dict_tres.keys())\n",
    "    valores = list(dict_tres.values())\n",
    "\n",
    "    plt.figure(figsize=(14,7)) \n",
    "    plt.xlabel('KT')\n",
    "    plt.ylabel('average c(KT)')\n",
    "\n",
    "    plt.scatter(claves, valores, s=1, marker=\"x\")\n",
    "\n",
    "    plt.savefig(\"plots/\" + name_graph.split('_')[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(name_graph):\n",
    "    full_graph_path = \"graphs/\" + name_graph + \".gexf\"\n",
    "    # Cargamos el grafo\n",
    "    G = nx.read_gexf(full_graph_path)\n",
    "    print(\"Cargado el grafo de la hora \" + name_graph.split('_')[-1] + ', numero de nodos: ' + str(G.number_of_nodes()) + ', numero de aristas: ' + str(G.number_of_edges()))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_plot(name_graph):\n",
    "    G = load_graph(name_graph)\n",
    "    dict_tres = calc_clust(G)\n",
    "    plot_clust(dict_tres, name_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado el grafo de la hora 437011, numero de nodos: 13169, numero de aristas: 193735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(graphs_folder, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".gexf\"):\n",
    "            calc_plot(name[:-5])\n",
    "            \n",
    "# Selecciono el grafo de la hora que nos interesa\n",
    "#name_graph = \"hashtags_sharing_users_437036\"\n",
    "# 437037 se corresponde con las 21:00 del 9n (momento explosion segun paper Yerali)\n",
    "#calc_plot(name_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = tresh_normalization(G, 1)\n",
    "#A graph is commonly classified as small-world if sigma>1.\n",
    "sigma = nx.smallworld.sigma(G)\n",
    "print(\"a\")\n",
    "# Values close to 0 mean that G has small-world characteristics.\n",
    "omega = nx.smallworld.omega(G)\n",
    "\n",
    "print(\"sigma: \", sigma, \", omega: \", omega)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
